{
  "analyticsCode": "",
  "pageLayout": "two-column",
  "basics": {
    "name": "Masood Salman Choudhury",
    "label": "Senior Data Engineer & AI Solutions Architect",
    "image": "/DP_cropped.jpg",
    "email": "MSalman5230@gmail.com",
    "url": "https://msalman.de",
    "summary": "Senior Data Engineer & AI Solutions Architect with 5+ years' experience delivering end-to-end data platforms and intelligent applications across fintech, SaaS, and industrial analytics. Expert in designing scalable data pipelines, building AI-powered systems with LLMs and machine learning models, and deploying robust cloud-native solutions on AWS, Azure, and GCP.",
    "theme": "blue",
    "location": {
      "address": "Manchester",
      "city": "Manchester",
      "countryCode": "GB",
      "region": "United Kingdom"
    },
    "profiles": [
      {
        "network": "LinkedIn",
        "icon": "mdi:linkedin",
        "username": "MSalman5230",
        "url": "https://linkedin.com/in/MSalman5230"
      },
      {
        "network": "GitHub",
        "icon": "mdi:github",
        "username": "MSalman5230",
        "url": "https://github.com/MSalman5230"
      },
      {
        "network": "Website",
        "icon": "mdi:web",
        "username": "msalman.de",
        "url": "https://msalman.de"
      }
    ],
    "beian": {
      "mint": "",
      "police": ""
    }
  },

  "education": [
    {
      "institution": "University of Liverpool",
      "url": "",
      "area": "MSc Business Analytics and Big Data",
      "studyType": "Masters",
      "startDate": "2020-11-01",
      "endDate": "2022-02-01"
    },
    {
      "institution": "Asian Institute of Management and Technology",
      "url": "",
      "area": "Bachelor of Business Administration",
      "studyType": "Bachelors",
      "startDate": "2016-08-01",
      "endDate": "2019-06-01",
      "location": "Guwahati, India",
      "keyModules": ["Statistics", "Mathematics", "Production & Operation Management"],
      "result": "First-Class"
    }
  ],
  "certificates": [
    {
      "name": "IBM Data Science Professional Certificate",
      "date": "",
      "url": "",
      "issuer": "IBM"
    },
    {
      "name": "Microsoft Certified: Azure Fundamentals (AZ-900)",
      "date": "",
      "url": "",
      "issuer": "Microsoft"
    },
    {
      "name": "Microsoft Certified: Azure AI Fundamentals (AI-900)",
      "date": "",
      "url": "",
      "issuer": "Microsoft"
    }
  ],
  "work": [
    {
      "name": "Helixiora",
      "position": "Senior Data Engineer & AI Solutions Architect",
      "location_type": "Remote",
      "location": "Netherlands",
      "url": "",
      "startDate": "2024-04-01",
      "endDate": null,
      "summary": "Lead data engineer delivering end-to-end solutions for multiple international clients across fintech, enterprise SaaS, and industrial analytics domains.",
      "highlights": [
        "Designed and deployed Azure data pipelines in Databricks (PySpark, SparkSQL) for large-scale data processing",
        "Led development of enterprise-grade Multi-Stage RAG system combining Python pipelines with LLMs and VectorDB",
        "Built end-to-end Azure data pipeline using App Functions and CosmosDB with Kimball dimensional modeling",
        "Developed full-stack AI SaaS app with OpenAI Assistant API, React Native, and PostgreSQL"
      ],
             "responsibilities": [
         "Designed, built, and deployed Azure data pipelines in Databricks (PySpark, SparkSQL) to ingest large-scale structured and semi-structured datasets from Blob Storage and Azure Cosmos DB, execute complex transformations, and persist curated features in Delta Lake for downstream machine learning workflows",
         "Led development of an enterprise-grade Multi-Stage RAG system for clients, combining Python-based data pipelines (Google Drive, Slack) with LLMs, Langchain, Reranker, and Pinecone VectorDB to deliver highly accurate, context-aware retrieval workflows",
         "Designed, built, and deployed an end-to-end Azure data pipeline using App Functions and CosmosDB, applying Kimball dimensional modeling for Power BI datasets with DAX-based measures, enabling KPI reporting and forecasting",
         "Led development of a full-stack AI SaaS app (Android and iOS) leveraging OpenAI Assistant API with a FastAPI backend, React Native (Expo) frontend, and PostgreSQL database, including OAuth 2.0 authentication and integrated Stripe payment processing",
         "Designed and implemented end-to-end CI/CD pipelines for fully automated deployment of containerized applications to AWS, ECS using Docker, Docker Compose, and infrastructure-as-code best practices (Terraform)",
         "Secured and deployed SaaS applications with SSL, reverse proxies, Zero Trust controls, and firewall rules, optimising load balancing for high availability",
         "Provided technical mentorship and conducted code reviews for junior and mid-level engineers, promoting best practices, improving code quality, and accelerating team growth"
       ],
      "skills": {
        "Python": "simple-icons:python",
        "Databricks": "simple-icons:databricks",
        "PySpark": "simple-icons:apachespark",
        "Delta Lake": "simple-icons:delta",
        "Langchain": "simple-icons:langchain",
        "Pinecone": "mdi:database-search",
        "React Native": "mdi:react",
        "PostgreSQL": "simple-icons:postgresql",
        "MySQL": "simple-icons:mysql",
        "Docker": "mdi:docker",
        "AWS": "simple-icons:amazonaws",
        "Azure": "simple-icons:microsoftazure",
        "Terraform": "simple-icons:terraform",
        "Git": "mdi:git"
      }
    },
    {
      "name": "Vaultoro",
      "position": "Senior Data Engineer",
      "location_type": "Remote",
      "location": "United Kingdom",
      "url": "",
      "startDate": "2022-02-01",
      "endDate": "2024-03-01",
      "summary": "Architected data warehouse solutions and led development of scalable ETL pipelines for financial data processing.",
      "highlights": [
        "Architected Kimball style star schema data warehouse using Elasticsearch and BigQuery",
        "Led implementation of scalable ETL pipelines with Python, GCP Dataflow, and Apache Airflow",
        "Co-led agile development of secure Savings Platform using FastAPI"
      ],
             "responsibilities": [
         "Architected a Kimball style star schema data warehouse using Elasticsearch and BigQuery, enabling real-time KPI dashboards in Kibana and empowering data-driven decision-making for stakeholders",
         "Led the design and implementation of multiple scalable ETL pipelines with Python, GCP Dataflow, Scrapy, and managed workflow orchestration with Apache Airflow, processing over 10 million financial data rows daily for real-time analytics",
         "Co-led the agile development of a secure, scalable Savings Platform using FastAPI, delivering the product in 3 months; currently manages $2M+ in monthly customer deposits",
         "Managed and optimized databases including MongoDB, PostgreSQL, Elasticsearch, and BigQuery by tuning queries, indexes, and partitions, resulting in significant performance improvements",
         "Conducted deep data analysis with Pandas to detect anomalies and identify potential fraud patterns, enhancing platform security",
         "Automated data validation workflows using Python scripts, ensuring pipeline integrity and achieving 100% uptime for critical microservices",
         "Deployed containerized applications with Docker and Kubernetes, ensuring high availability, scalability, and streamlined CI/CD operations",
         "Developed and implemented a Random Forest classification model to identify high-value clients during signup, enabling personalized onboarding experiences",
         "Configured and monitored Google Analytics and Tag Manager dashboards to track user behavior and support data-driven marketing strategies"
       ],
      "skills": {
        "Python": "simple-icons:python",
        "Elasticsearch": "simple-icons:elasticsearch",
        "BigQuery": "simple-icons:googlebigquery",
        "Kibana": "simple-icons:kibana",
        "GCP": "simple-icons:googlecloud",
        "FastAPI": "simple-icons:fastapi",
        "MongoDB": "simple-icons:mongodb",
        "PostgreSQL": "simple-icons:postgresql",
        "Apache Airflow": "simple-icons:apacheairflow",
        "Pandas": "simple-icons:pandas",
        "Docker": "mdi:docker",
        "Kubernetes": "simple-icons:kubernetes"
      }
    },
    {
      "name": "SoftCrop IT",
      "position": "Data Analyst",
      "location_type": "On-site",
      "location": "Guwahati, India",
      "url": "",
      "startDate": "2019-06-01",
      "endDate": "2020-10-01",
      "summary": "Delivered actionable insights via Tableau dashboards and automated data collection processes.",
      "highlights": [
        "Delivered actionable insights via Tableau dashboards (waterfall/cohort analysis)",
        "Automated competitor data scraping (Scrapy) and ETL into MySQL"
      ],
             "responsibilities": [
         "Delivered actionable insights via Tableau dashboards (waterfall/cohort analysis), improving stakeholder decision-making",
         "Automated competitor data scraping (Scrapy) and ETL into MySQL, reducing manual effort by 50%",
         "Analyzed sales and geographic data to guide strategic fibre network expansion"
       ],
      "skills": {
        "Python": "simple-icons:python",
        "Tableau": "simple-icons:tableau",
        "MySQL": "simple-icons:mysql",
        "Scrapy": "simple-icons:scrapy",
        "Pandas": "simple-icons:pandas"
      }
    }
  ],
  "skills": [
    {
      "name": "Python",
      "icon": "simple-icons:python",
      "level": "Expert",
      "keywords": [
        "Data Engineering",
        "Machine Learning",
        "Backend Development",
        "Automation"
      ]
    },
    {
      "name": "Databricks",
      "icon": "simple-icons:databricks",
      "level": "Expert",
      "keywords": [
        "Data Processing",
        "Big Data",
        "PySpark",
        "Delta Lake"
      ]
    },
    {
      "name": "PySpark",
      "icon": "simple-icons:apachespark",
      "level": "Expert",
      "keywords": [
        "Big Data Processing",
        "Distributed Computing",
        "Data Transformation",
        "ETL Pipelines"
      ]
    },
    {
      "name": "Delta Lake",
      "icon": "simple-icons:delta",
      "level": "Expert",
      "keywords": [
        "Data Lake",
        "ACID Transactions",
        "Data Versioning",
        "Big Data Storage"
      ]
    },
    {
      "name": "Langchain",
      "icon": "simple-icons:langchain",
      "level": "Expert",
      "keywords": [
        "LLM Integration",
        "RAG Systems",
        "AI Applications",
        "Prompt Engineering"
      ]
    },
    {
      "name": "Pinecone",
      "icon": "mdi:database-search",
      "level": "Expert",
      "keywords": [
        "Vector Database",
        "Semantic Search",
        "AI Applications",
        "RAG Systems"
      ]
    },
    {
      "name": "React Native",
      "icon": "mdi:react",
      "level": "Intermediate",
      "keywords": [
        "Mobile Development",
        "Cross-platform",
        "JavaScript",
        "UI Development"
      ]
    },
    {
      "name": "PostgreSQL",
      "icon": "simple-icons:postgresql",
      "level": "Expert",
      "keywords": [
        "Database Management",
        "SQL",
        "Data Storage",
        "Backend"
      ]
    },
    {
      "name": "MySQL",
      "icon": "simple-icons:mysql",
      "level": "Intermediate",
      "keywords": [
        "Database Management",
        "SQL",
        "Data Storage",
        "Backend"
      ]
    },
    {
      "name": "Docker",
      "icon": "mdi:docker",
      "level": "Expert",
      "keywords": [
        "Containerization",
        "DevOps",
        "Deployment",
        "Microservices"
      ]
    },
    {
      "name": "AWS",
      "icon": "simple-icons:amazonaws",
      "level": "Expert",
      "keywords": [
        "Cloud Computing",
        "ECS",
        "Lambda",
        "Infrastructure"
      ]
    },
    {
      "name": "Azure",
      "icon": "simple-icons:microsoftazure",
      "level": "Expert",
      "keywords": [
        "Cloud Computing",
        "Functions",
        "CosmosDB",
        "Data Platform"
      ]
    },
    {
      "name": "GCP",
      "icon": "simple-icons:googlecloud",
      "level": "Intermediate",
      "keywords": [
        "Cloud Computing",
        "BigQuery",
        "Dataflow",
        "Pub/Sub"
      ]
    },
    {
      "name": "Terraform",
      "icon": "simple-icons:terraform",
      "level": "Intermediate",
      "keywords": [
        "Infrastructure as Code",
        "DevOps",
        "Cloud Provisioning",
        "Automation"
      ]
    },
    {
      "name": "Git",
      "icon": "mdi:git",
      "level": "Expert",
      "keywords": [
        "Version Control",
        "Collaboration",
        "Source Code Management",
        "CI/CD"
      ]
    },
    {
      "name": "Elasticsearch",
      "icon": "simple-icons:elasticsearch",
      "level": "Intermediate",
      "keywords": [
        "Search Engine",
        "Data Indexing",
        "Analytics",
        "Big Data"
      ]
    },
    {
      "name": "BigQuery",
      "icon": "simple-icons:googlebigquery",
      "level": "Intermediate",
      "keywords": [
        "Data Warehouse",
        "Big Data Analytics",
        "SQL",
        "Cloud Storage"
      ]
    },
    {
      "name": "FastAPI",
      "icon": "simple-icons:fastapi",
      "level": "Expert",
      "keywords": [
        "Web Framework",
        "API Development",
        "Python",
        "Backend"
      ]
    },
    {
      "name": "MongoDB",
      "icon": "simple-icons:mongodb",
      "level": "Intermediate",
      "keywords": [
        "NoSQL Database",
        "Document Storage",
        "Data Management",
        "Backend"
      ]
    },
    {
      "name": "Apache Airflow",
      "icon": "simple-icons:apacheairflow",
      "level": "Intermediate",
      "keywords": [
        "Workflow Orchestration",
        "ETL Pipelines",
        "Data Engineering",
        "Automation"
      ]
    },
    {
      "name": "Pandas",
      "icon": "simple-icons:pandas",
      "level": "Expert",
      "keywords": [
        "Data Analysis",
        "Data Manipulation",
        "Python",
        "Analytics"
      ]
    },
    {
      "name": "Kubernetes",
      "icon": "simple-icons:kubernetes",
      "level": "Intermediate",
      "keywords": [
        "Container Orchestration",
        "DevOps",
        "Scalability",
        "Microservices"
      ]
    },
    {
      "name": "Tableau",
      "icon": "simple-icons:tableau",
      "level": "Intermediate",
      "keywords": [
        "Data Visualization",
        "Business Intelligence",
        "Analytics",
        "Reporting"
      ]
    },
    {
      "name": "Scrapy",
      "icon": "simple-icons:scrapy",
      "level": "Intermediate",
      "keywords": [
        "Web Scraping",
        "Data Collection",
        "Python",
        "Automation"
      ]
    }
  ],
  "languages": [
    {
      "language": "English",
      "fluency": "Fluent"
    },
    {
      "language": "Bengali",
      "fluency": "Native speaker"
    }
  ],
  "interests": [
    {
      "name": "Data Science",
      "keywords": [
        "Machine Learning",
        "AI",
        "Big Data Analytics"
      ]
    },
    {
      "name": "Technology",
      "keywords": [
        "Cloud Computing",
        "DevOps",
        "Software Architecture"
      ]
    }
  ],
  "references": [
    {
      "name": "Available upon request",
      "reference": "Professional references available upon request"
    }
  ],
  "projects": [
    {
      "name": "ETA Prediction for Container Ports using Machine Learning",
      
      "isActive": false,
      "description": "MSc project at University of Liverpool predicting ship delays with 80% accuracy using machine learning techniques.",
      "highlights": [
        "üéØ Predicted ship delays 10+ days in advance with 80% accuracy",
        "üîß Cleaned and engineered features using Pandas, NumPy, and Pearson correlation",
        "ü§ñ Evaluated multiple ML models (SVM, DT, RF, NN) and selected Random Forest",
        "üöÄ Deployed the model with FastAPI for real-time predictions"
      ],
      "url": "",
      "github": ""
    },
    {
      "name": "Diabetes Prediction using XGBoost",
      
      "isActive": true,
      "description": "Personal project for self-learning diabetes prediction using machine learning techniques.",
      "highlights": [
        "üìä Exploratory Data Analysis (EDA) with Seaborn and UMAP visualization",
        "‚öôÔ∏è Tuned XGBoost hyperparameters with Optuna and ML-Flow",
        "üåê Deployed using Streamlit framework",
        "üîó Live Demo available online"
      ],
      "url": "https://PredictDiabetes.msalman.de",
      "github": ""
    }
  ]
}
